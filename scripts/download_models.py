#!/usr/bin/env python3
"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏–∑ GitHub Releases

–°–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–µ–π –∏–∑ GitHub Releases,
—Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç –∞—Ä—Ö–∏–≤ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–æ–≤.

Usage:
    python scripts/download_models.py [--tag TAG] [--force]
    
    --tag TAG: –°–∫–∞—á–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é - latest)
    --force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
"""

import os
import argparse
import hashlib
import requests
import tarfile
import sys
from pathlib import Path
from typing import Optional, Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
REPO = "Arsystem808/AI-trading"
MODELS_DIR = Path("models")
CONFIG_DIR = Path("config")
EXTRACT_DIR = Path(".")

def get_release_info(tag: Optional[str] = None) -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–ª–∏–∑–µ.
    
    Args:
        tag: –¢–µ–≥ –≤–µ—Ä—Å–∏–∏ (None = latest)
        
    Returns:
        dict: –î–∞–Ω–Ω—ã–µ —Ä–µ–ª–∏–∑–∞
    """
    if tag:
        url = f"https://api.github.com/repos/{REPO}/releases/tags/{tag}"
    else:
        url = f"https://api.github.com/repos/{REPO}/releases/latest"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 404:
            print(f"‚ùå –†–µ–ª–∏–∑ –Ω–µ –Ω–∞–π–¥–µ–Ω: {tag or 'latest'}")
        else:
            print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–µ–ª–∏–∑–µ: {e}")
        sys.exit(1)


def verify_checksum(file_path: Path, expected_hash: Optional[str] = None) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SHA256 —á–µ–∫—Å—É–º–º—É —Ñ–∞–π–ª–∞.
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        expected_hash: –û–∂–∏–¥–∞–µ–º—ã–π —Ö–µ—à (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        bool: True –µ—Å–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—à–ª–∞
    """
    if not expected_hash:
        return True
    
    sha256_hash = hashlib.sha256()
    
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            sha256_hash.update(chunk)
    
    actual_hash = sha256_hash.hexdigest()
    
    if actual_hash.lower() != expected_hash.lower():
        print(f"‚ö†Ô∏è  Checksum mismatch!")
        print(f"   Expected: {expected_hash}")
        print(f"   Got:      {actual_hash}")
        return False
    
    print("‚úÖ Checksum verified!")
    return True


def download_file(url: str, filename: str) -> bool:
    """
    –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º.
    
    Args:
        url: URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        filename: –ò–º—è —Å–æ—Ö—Ä–∞–Ω—è–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞
        
    Returns:
        bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
    """
    try:
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(filename, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    downloaded += len(chunk)
                    
                    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                    if total_size > 0:
                        percent = (downloaded / total_size) * 100
                        bar_length = 40
                        filled = int(bar_length * downloaded / total_size)
                        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
                        print(f'\r[{bar}] {percent:.1f}%', end='', flush=True)
        
        print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏: {e}")
        return False


def extract_archive(filename: str, extract_to: Path = EXTRACT_DIR) -> bool:
    """
    –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å tar.gz –∞—Ä—Ö–∏–≤.
    
    Args:
        filename: –ò–º—è –∞—Ä—Ö–∏–≤–∞
        extract_to: –ö—É–¥–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å
        
    Returns:
        bool: True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
    """
    try:
        with tarfile.open(filename, 'r:gz') as tar:
            # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞ (–ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–µ–π)
            members = tar.getmembers()
            
            for member in members:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ path traversal
                if member.name.startswith(('/', '..')):
                    print(f"‚ö†Ô∏è  Suspicious path in archive: {member.name}")
                    continue
                
                tar.extract(member, extract_to)
            
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ: {e}")
        return False


def verify_models(force: bool = False) -> None:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏.
    
    Args:
        force: –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
    """
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π...\n")
    
    if not MODELS_DIR.exists():
        print("‚ùå –ü–∞–ø–∫–∞ models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    # –ü–æ–∏—Å–∫ –º–æ–¥–µ–ª–µ–π
    model_patterns = [
        '*.joblib',
        '*.pkl',
        '**/*.joblib',
        '**/*.pkl'
    ]
    
    all_models = []
    for pattern in model_patterns:
        all_models.extend(MODELS_DIR.glob(pattern))
    
    # –ò—Å–∫–ª—é—á–∏—Ç—å scalers
    models = [
        f for f in all_models 
        if 'scaler' not in f.name.lower()
    ]
    
    if not models:
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return
    
    print(f"‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π:\n")
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∞–≥–µ–Ω—Ç—É
    by_agent = {}
    for model in sorted(models):
        # –ò–∑–≤–ª–µ—á—å –∏–º—è –∞–≥–µ–Ω—Ç–∞ –∏–∑ –ø—É—Ç–∏
        parts = model.parts
        agent = parts[-2] if len(parts) > 1 else "root"
        
        if agent not in by_agent:
            by_agent[agent] = []
        
        by_agent[agent].append(model)
    
    # –í—ã–≤–æ–¥ –ø–æ –∞–≥–µ–Ω—Ç–∞–º
    for agent, agent_models in sorted(by_agent.items()):
        print(f"üìÅ {agent}:")
        
        for model in agent_models:
            size_kb = model.stat().st_size / 1024
            print(f"  üì¶ {model.name} ({size_kb:.1f} KB)")
        
        print()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥–∏
    if CONFIG_DIR.exists():
        configs = list(CONFIG_DIR.glob('*.json'))
        print(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(configs)} –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π")


def cleanup(filename: str) -> None:
    """
    –£–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã.
    
    Args:
        filename: –§–∞–π–ª –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    """
    try:
        Path(filename).unlink()
        print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {filename}: {e}")


def download_latest_models(tag: Optional[str] = None, force: bool = False) -> None:
    """
    –°–∫–∞—á–∞—Ç—å –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ GitHub Release.
    
    Args:
        tag: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è (None = latest)
        force: –ü–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–æ–¥–µ–ª–∏
    """
    print("üîç –ü–æ–∏—Å–∫ —Ä–µ–ª–∏–∑–∞ —Å –º–æ–¥–µ–ª—è–º–∏...")
    
    # –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–ª–∏–∑
    release = get_release_info(tag)
    
    release_tag = release['tag_name']
    release_date = release['published_at'][:10]
    release_name = release.get('name', release_tag)
    
    print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ä–µ–ª–∏–∑: {release_name} ({release_tag}, {release_date})")
    
    # –ù–∞–π—Ç–∏ –∞—Ä—Ö–∏–≤ —Å –º–æ–¥–µ–ª—è–º–∏
    archive_asset = None
    checksum_asset = None
    
    for asset in release['assets']:
        name = asset['name']
        
        if name.endswith('.tar.gz') and 'sha256' not in name:
            archive_asset = asset
        elif name.endswith('.sha256') or 'sha256' in name:
            checksum_asset = asset
    
    if not archive_asset:
        print("‚ùå –ê—Ä—Ö–∏–≤ —Å –º–æ–¥–µ–ª—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ä–µ–ª–∏–∑–µ!")
        sys.exit(1)
    
    filename = archive_asset['name']
    download_url = archive_asset['browser_download_url']
    size_mb = archive_asset['size'] / 1024 / 1024
    
    print(f"\nüì¶ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {filename} ({size_mb:.1f} MB)")
    print(f"üîó URL: {download_url}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∞–π–ª–æ–≤
    if MODELS_DIR.exists() and not force:
        existing = list(MODELS_DIR.glob('*.joblib')) + list(MODELS_DIR.glob('*.pkl'))
        
        if existing:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ CI –æ–∫—Ä—É–∂–µ–Ω–∏—è
            # GitHub Actions —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç GITHUB_ACTIONS=true
            # –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ CI —Å–∏—Å—Ç–µ–º —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç CI=true
            is_ci = os.getenv("GITHUB_ACTIONS") == "true" or os.getenv("CI") == "true"
            
            if is_ci:
                # –í CI –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
                print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(existing)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π")
                print("   ü§ñ CI environment detected - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
            else:
                # –í –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ —Å–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(existing)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π")
                print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏")
                
                response = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ")
                if response.lower() != 'y':
                    print("‚ùå –û—Ç–º–µ–Ω–µ–Ω–æ")
                    sys.exit(0)
    
    # –°–∫–∞—á–∞—Ç—å –∞—Ä—Ö–∏–≤
    if not download_file(download_url, filename):
        sys.exit(1)
    
    print(f"‚úÖ –°–∫–∞—á–∞–Ω–æ: {filename}")
    
    # –°–∫–∞—á–∞—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å checksum (–µ—Å–ª–∏ –µ—Å—Ç—å)
    expected_hash = None
    
    if checksum_asset:
        checksum_url = checksum_asset['browser_download_url']
        checksum_file = checksum_asset['name']
        
        print(f"\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ checksums...")
        
        if download_file(checksum_url, checksum_file):
            try:
                with open(checksum_file, 'r') as f:
                    # –§–æ—Ä–º–∞—Ç: <hash> <filename>
                    line = f.read().strip().split()
                    expected_hash = line[0]
                
                Path(checksum_file).unlink()
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å checksum: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å checksum
    if expected_hash:
        print(f"\nüîê –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
        
        if not verify_checksum(Path(filename), expected_hash):
            print("‚ùå Checksum –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç! –§–∞–π–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
            cleanup(filename)
            sys.exit(1)
    
    # –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤
    print(f"\nüìÇ –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–∞...")
    
    if not extract_archive(filename):
        cleanup(filename)
        sys.exit(1)
    
    print("‚úÖ –ê—Ä—Ö–∏–≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω!")
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª–∏
    verify_models(force)
    
    # –£–¥–∞–ª–∏—Ç—å –∞—Ä—Ö–∏–≤
    cleanup(filename)
    
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –ú–æ–¥–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.\n")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Download models from GitHub Releases",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--tag',
        type=str,
        help='Specific release tag (default: latest)'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='Overwrite existing models'
    )
    
    parser.add_argument(
        '--list',
        action='store_true',
        help='List available releases'
    )
    
    args = parser.parse_args()
    
    # –°–ø–∏—Å–æ–∫ —Ä–µ–ª–∏–∑–æ–≤
    if args.list:
        print("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ä–µ–ª–∏–∑–æ–≤...")
        
        try:
            url = f"https://api.github.com/repos/{REPO}/releases"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            releases = response.json()
            
            print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω–æ —Ä–µ–ª–∏–∑–æ–≤: {len(releases)}\n")
            
            for release in releases[:10]:  # –ü–æ–∫–∞–∑–∞—Ç—å 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö
                tag = release['tag_name']
                date = release['published_at'][:10]
                name = release.get('name', tag)
                
                print(f"  ‚Ä¢ {name} ({tag}) - {date}")
            
            print()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            sys.exit(1)
        
        return
    
    # –°–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª–∏
    download_latest_models(tag=args.tag, force=args.force)


if __name__ == '__main__':
    main()
