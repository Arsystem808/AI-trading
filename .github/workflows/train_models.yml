name: Nightly Training

on:
  schedule:
    - cron: "0 2 * * *"   # 02:00 UTC (05:00 MSK) –µ–∂–µ–¥–Ω–µ–≤–Ω–æ
  workflow_dispatch:
    inputs:
      canary:
        description: "Create canary release (experimental)"
        type: boolean
        default: false
      symbols_override:
        description: "Override symbols list (space-separated)"
        type: string
        required: false

permissions:
  contents: write
  actions: read
  id-token: write

concurrency:
  group: nightly-training-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  train:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    env:
      POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
      POLYGON_TIER: ${{ vars.POLYGON_TIER || 'basic' }}
      
      # Core symbols (production)
      SYMBOLS: ${{ inputs.symbols_override || 'AAPL SPY BTCUSD ETHUSD QQQ TLT TSLA IBIT EETH MSFT OXY BITO MARA SOXL NVDA GS GLD' }}
      START_DATE: "2019-01-01"
      EPOCHS: "12"
      
      # Hugging Face (optional)
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      HF_REPO: ${{ vars.HF_REPO }}
      HF_PRIVATE: "true"
      
      # Release management
      KEEP_RELEASES: 7
      MAX_FAILURE_RATE: 30  # Max % of failed symbols before abort

    steps:
      # ========================================
      # 1. Setup & Validation
      # ========================================
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check merge conflicts
        shell: bash
        run: |
          if git grep -nE '^(<<<<<<<|=======|>>>>>>>)' -- . >/dev/null 2>&1; then
            echo "‚ùå Unresolved merge markers found:"
            git grep -nE '^(<<<<<<<|=======|>>>>>>>)' -- .
            exit 1
          fi
          echo "‚úÖ No merge conflicts"

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: requirements.txt

      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          pip install huggingface_hub  # –¥–ª—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
          echo "‚úÖ Dependencies installed"

      - name: Verify API key
        shell: bash
        run: |
          if [ -z "${POLYGON_API_KEY}" ]; then
            echo "‚ùå POLYGON_API_KEY not configured"
            exit 1
          fi
          echo "‚úÖ API key validated (tier: ${POLYGON_TIER})"

      - name: Set runtime variables
        shell: bash
        run: |
          echo "END_DATE=$(date -u +%Y-%m-%d)" >> "$GITHUB_ENV"
          echo "RUN_DATE=$(date -u +%Y%m%d_%H%M%S)" >> "$GITHUB_ENV"
          echo "IS_CANARY=${{ inputs.canary }}" >> "$GITHUB_ENV"
          
          # Create directories
          mkdir -p models configs artifacts logs
          
          echo "üìÖ Training date: $(date -u +%Y-%m-%d)"
          echo "üè∑Ô∏è  Run ID: ${{ github.run_id }}"

      - name: Monitor initial disk space
        shell: bash
        run: |
          echo "üíæ Initial disk usage:"
          df -h
          
          AVAILABLE_GB=$(df -BG . | tail -1 | awk '{print $4}' | sed 's/G//')
          if [ "$AVAILABLE_GB" -lt 5 ]; then
            echo "‚ö†Ô∏è  WARNING: Low disk space (${AVAILABLE_GB}GB remaining)"
          fi

      # ========================================
      # 2. Training with Rate Limiting & Retry
      # ========================================
      - name: Train models (all symbols)
        shell: bash
        env:
          CI_DRY_RUN: "0"
        run: |
          set -euo pipefail
          
          # Rate limiting based on Polygon tier
          if [ "$POLYGON_TIER" = "basic" ]; then
            DELAY_BETWEEN_SYMBOLS=20
            RETRY_DELAY=60
            echo "‚ö†Ô∏è  Using Polygon Basic tier (5 req/sec) - adding delays"
          elif [ "$POLYGON_TIER" = "starter" ]; then
            DELAY_BETWEEN_SYMBOLS=10
            RETRY_DELAY=30
            echo "‚ÑπÔ∏è  Using Polygon Starter tier"
          else
            DELAY_BETWEEN_SYMBOLS=5
            RETRY_DELAY=15
            echo "‚ÑπÔ∏è  Using Polygon Advanced tier"
          fi
          
          IFS=' ' read -r -a SYMBOLS_ARR <<< "$SYMBOLS"
          FAILED_SYMBOLS=()
          SUCCESS_COUNT=0
          
          echo ""
          echo "========================================="
          echo "üéØ Training ${#SYMBOLS_ARR[@]} symbols"
          echo "========================================="
          
          for i in "${!SYMBOLS_ARR[@]}"; do
            SYMBOL="${SYMBOLS_ARR[$i]}"
            echo ""
            echo "========================================="
            echo "[$((i+1))/${#SYMBOLS_ARR[@]}] Training: ${SYMBOL}"
            echo "========================================="
            
            # Train with retry logic
            RETRIES=3
            SUCCESS=0
            
            for attempt in $(seq 1 $RETRIES); do
              echo "Attempt $attempt/$RETRIES for ${SYMBOL}..."
              
              if timeout 1200 python scripts/train.py \
                --symbol "${SYMBOL}" \
                --start "${START_DATE}" \
                --end "${END_DATE}" \
                --epochs "${EPOCHS}" \
                --artifacts-dir "artifacts/${SYMBOL}" \
                --models-dir "models" \
                --configs-dir "configs" 2>&1 | tee "logs/train_${SYMBOL}.log"; then
                
                SUCCESS=1
                SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                echo "‚úÖ Training succeeded for ${SYMBOL}"
                break
              else
                EXIT_CODE=$?
                echo "‚ö†Ô∏è  Training failed for ${SYMBOL} (attempt $attempt/$RETRIES, exit code: $EXIT_CODE)"
                
                # Check for rate limit errors
                if grep -qE "rate limit|429|Too Many Requests|API key" "logs/train_${SYMBOL}.log" 2>/dev/null; then
                  echo "Rate limit detected, waiting ${RETRY_DELAY}s before retry..."
                  sleep "$RETRY_DELAY"
                elif [ $EXIT_CODE -eq 124 ]; then
                  echo "Timeout detected (20min), skipping retries"
                  break
                else
                  echo "Waiting 10s before retry..."
                  sleep 10
                fi
              fi
            done
            
            if [ $SUCCESS -eq 0 ]; then
              FAILED_SYMBOLS+=("$SYMBOL")
              echo "‚ùå Training failed for ${SYMBOL} after $RETRIES attempts"
            fi
            
            # Cleanup intermediate artifacts to save disk space
            if [ -d "artifacts/${SYMBOL}" ]; then
              find "artifacts/${SYMBOL}" -name "*.png" -delete 2>/dev/null || true
              find "artifacts/${SYMBOL}" -name "checkpoint_*.pkl" -delete 2>/dev/null || true
            fi
            
            # Delay between symbols to respect rate limits
            if [ $((i+1)) -lt ${#SYMBOLS_ARR[@]} ]; then
              echo "Waiting ${DELAY_BETWEEN_SYMBOLS}s before next symbol..."
              sleep "$DELAY_BETWEEN_SYMBOLS"
            fi
          done
          
          # Report results
          echo ""
          echo "========================================="
          echo "üìä Training Summary"
          echo "========================================="
          echo "Total symbols: ${#SYMBOLS_ARR[@]}"
          echo "Succeeded: $SUCCESS_COUNT"
          echo "Failed: ${#FAILED_SYMBOLS[@]}"
          
          if [ ${#FAILED_SYMBOLS[@]} -gt 0 ]; then
            echo ""
            echo "Failed symbols: ${FAILED_SYMBOLS[*]}"
            echo "FAILED_SYMBOLS=${FAILED_SYMBOLS[*]}" >> "$GITHUB_ENV"
            echo "FAILED_COUNT=${#FAILED_SYMBOLS[@]}" >> "$GITHUB_ENV"
            
            # Calculate failure rate
            FAIL_RATE=$(( ${#FAILED_SYMBOLS[@]} * 100 / ${#SYMBOLS_ARR[@]} ))
            echo "FAILURE_RATE=$FAIL_RATE" >> "$GITHUB_ENV"
            
            # Fail if too many failures
            if [ $FAIL_RATE -gt "$MAX_FAILURE_RATE" ]; then
              echo ""
              echo "‚ùå Failure rate too high: ${FAIL_RATE}% (threshold: ${MAX_FAILURE_RATE}%)"
              echo "Aborting release creation."
              exit 1
            else
              echo "‚ö†Ô∏è  Failure rate acceptable: ${FAIL_RATE}% (threshold: ${MAX_FAILURE_RATE}%)"
            fi
          else
            echo "‚úÖ All symbols trained successfully"
            echo "FAILED_SYMBOLS=" >> "$GITHUB_ENV"
            echo "FAILED_COUNT=0" >> "$GITHUB_ENV"
            echo "FAILURE_RATE=0" >> "$GITHUB_ENV"
          fi

      - name: Monitor disk space after training
        if: always()
        shell: bash
        run: |
          echo "üíæ Disk usage after training:"
          df -h
          du -sh models/ artifacts/ logs/ 2>/dev/null || true

      - name: Calibrate confidence
        shell: bash
        run: |
          python scripts/calibrate_confidence.py || echo "‚ö†Ô∏è  Calibration failed (non-critical)"

      - name: Train Octopus meta-model
        shell: bash
        run: |
          python scripts/train_octopus_meta.py || echo "‚ö†Ô∏è  Octopus training failed (non-critical)"

      - name: Sanitize filenames
        shell: bash
        run: |
          echo "üîß Sanitizing filenames (removing colons)..."
          for dir in models artifacts configs; do
            if [ -d "$dir" ]; then
              find "$dir" -type f -name '*:*' 2>/dev/null | while IFS= read -r file; do
                new_file="${file//:/_}"
                mkdir -p "$(dirname "$new_file")"
                mv "$file" "$new_file"
                echo "Renamed: $file ‚Üí $new_file"
              done || true
            fi
          done

      # ========================================
      # 3. Model Validation (CRITICAL)
      # ========================================
      - name: Validate trained models
        shell: bash
        run: |
          set -euo pipefail
          
          echo "========================================="
          echo "üîç Validating Trained Models"
          echo "========================================="
          
          VALIDATION_FAILED=0
          VALIDATED_COUNT=0
          IFS=' ' read -r -a SYMBOLS_ARR <<< "$SYMBOLS"
          
          for SYMBOL in "${SYMBOLS_ARR[@]}"; do
            SAFE_SYMBOL="${SYMBOL//:/_}"
            
            # Try multiple naming patterns
            MODEL_PATHS=(
              "models/arxora_m7pro_${SAFE_SYMBOL}.joblib"
              "models/m7_${SAFE_SYMBOL}.joblib"
              "models/${SAFE_SYMBOL}.joblib"
            )
            
            MODEL_FOUND=0
            for MODEL_PATH in "${MODEL_PATHS[@]}"; do
              if [ -f "$MODEL_PATH" ]; then
                MODEL_FOUND=1
                
                # Validate model
                python - <<PYTHON_SCRIPT || { echo "‚ùå Validation failed for $SYMBOL"; VALIDATION_FAILED=1; continue 2; }
          import sys
          import joblib
          import numpy as np
          from pathlib import Path
          
          model_path = Path("$MODEL_PATH")
          symbol = "$SYMBOL"
          
          try:
              # Load model
              model = joblib.load(model_path)
              
              # Check structure
              if not hasattr(model, 'predict'):
                  print(f"‚ùå {symbol}: Model has no predict() method")
                  sys.exit(1)
              
              # Extract feature count
              n_features = None
              if hasattr(model, 'n_features_in_'):
                  n_features = model.n_features_in_
              elif hasattr(model, 'booster_'):
                  if hasattr(model.booster_, 'feature_name'):
                      feature_names = model.booster_.feature_name()
                      n_features = len(feature_names) if feature_names else None
              
              if n_features is None:
                  print(f"‚ö†Ô∏è  {symbol}: Cannot determine feature count, using fallback")
                  n_features = 50
              
              # Test prediction
              X_test = np.random.randn(5, n_features)
              
              if hasattr(model, 'predict_proba'):
                  preds = model.predict_proba(X_test)
                  
                  # Validate probabilities
                  if not (0 <= preds.min() and preds.max() <= 1.1):  # Allow slight numerical error
                      print(f"‚ùå {symbol}: Invalid probabilities (min={preds.min():.3f}, max={preds.max():.3f})")
                      sys.exit(1)
                  
                  print(f"‚úÖ {symbol}: predict_proba OK (shape={preds.shape}, features={n_features})")
              else:
                  preds = model.predict(X_test)
                  print(f"‚úÖ {symbol}: predict OK (shape={preds.shape}, features={n_features})")
              
              # Check file size
              size_mb = model_path.stat().st_size / (1024 * 1024)
              if size_mb < 0.01:
                  print(f"‚ùå {symbol}: Model suspiciously small ({size_mb:.3f} MB)")
                  sys.exit(1)
              
              print(f"   Size: {size_mb:.2f} MB")
              
          except Exception as e:
              print(f"‚ùå {symbol}: Validation error - {e}")
              import traceback
              traceback.print_exc()
              sys.exit(1)
          PYTHON_SCRIPT
                
                VALIDATED_COUNT=$((VALIDATED_COUNT + 1))
                break
              fi
            done
            
            if [ $MODEL_FOUND -eq 0 ]; then
              # Only error if training didn't fail
              if [[ ! " ${FAILED_SYMBOLS[@]:-} " =~ " ${SYMBOL} " ]]; then
                echo "‚ùå Model not found for ${SYMBOL} (tried: ${MODEL_PATHS[*]})"
                VALIDATION_FAILED=1
              else
                echo "‚ö†Ô∏è  Model not found for ${SYMBOL} (training failed, skipping)"
              fi
            fi
          done
          
          echo ""
          echo "========================================="
          echo "Validation Results"
          echo "========================================="
          echo "Validated: $VALIDATED_COUNT"
          echo "Failed: $VALIDATION_FAILED"
          
          if [ $VALIDATION_FAILED -gt 0 ]; then
            echo ""
            echo "‚ùå MODEL VALIDATION FAILED"
            echo "One or more models failed validation."
            echo "Release will NOT be created."
            exit 1
          fi
          
          echo "‚úÖ All models validated successfully"

      - name: Generate model statistics
        shell: bash
        run: |
          python - <<'PYTHON_SCRIPT'
          import json
          from pathlib import Path
          import joblib
          from datetime import datetime
          
          models_dir = Path("models")
          stats = {
              "generated_at": datetime.utcnow().isoformat(),
              "run_id": "${{ github.run_id }}",
              "models": {}
          }
          
          for model_file in sorted(models_dir.glob("*.joblib")):
              try:
                  model = joblib.load(model_file)
                  
                  stat = {
                      "file": model_file.name,
                      "size_mb": round(model_file.stat().st_size / (1024 * 1024), 2),
                      "has_predict": hasattr(model, "predict"),
                      "has_predict_proba": hasattr(model, "predict_proba"),
                  }
                  
                  # Extract feature info
                  if hasattr(model, 'n_features_in_'):
                      stat["n_features"] = model.n_features_in_
                  elif hasattr(model, 'booster_'):
                      if hasattr(model.booster_, 'feature_name'):
                          names = model.booster_.feature_name()
                          stat["n_features"] = len(names) if names else None
                          if names:
                              stat["feature_names"] = list(names)[:10]  # First 10
                  
                  stats["models"][model_file.stem] = stat
                  
              except Exception as e:
                  stats["models"][model_file.stem] = {"error": str(e)}
          
          # Summary
          stats["summary"] = {
              "total_models": len(stats["models"]),
              "total_size_mb": round(sum(
                  s.get("size_mb", 0) for s in stats["models"].values()
              ), 2),
              "successful": sum(
                  1 for s in stats["models"].values() if "error" not in s
              ),
              "failed": sum(
                  1 for s in stats["models"].values() if "error" in s
              )
          }
          
          # Save
          with open("models_stats.json", "w") as f:
              json.dump(stats, f, indent=2)
          
          print("üìä Model Statistics:")
          print(json.dumps(stats["summary"], indent=2))
          PYTHON_SCRIPT
          
          echo "MODEL_STATS_GENERATED=true" >> "$GITHUB_ENV"

      # ========================================
      # 4. Package Models
      # ========================================
      - name: Package models
        shell: bash
        run: |
          echo "üì¶ Packaging models..."
          
          # Ensure directories exist
          mkdir -p models configs
          
          # Create tarball
          tar -czf "models-${RUN_DATE}.tar.gz" models/ configs/ || {
            echo "‚ö†Ô∏è  Failed to create full archive, trying models only"
            tar -czf "models-${RUN_DATE}.tar.gz" models/
          }
          
          # Verify archive
          if [ ! -f "models-${RUN_DATE}.tar.gz" ]; then
            echo "‚ùå Archive not created"
            exit 1
          fi
          
          # Check size
          SIZE_MB=$(du -m "models-${RUN_DATE}.tar.gz" | cut -f1)
          echo "Archive size: ${SIZE_MB} MB"
          
          if [ "$SIZE_MB" -lt 1 ]; then
            echo "‚ö†Ô∏è  WARNING: Archive suspiciously small (< 1 MB)"
          fi
          
          # Generate checksums
          sha256sum "models-${RUN_DATE}.tar.gz" > "models-${RUN_DATE}.tar.gz.sha256"
          
          echo "‚úÖ Package created: models-${RUN_DATE}.tar.gz (${SIZE_MB} MB)"

      # ========================================
      # 5. Cleanup Old Releases
      # ========================================
      - name: Cleanup old releases
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üóëÔ∏è  Cleaning up old releases (keeping last $KEEP_RELEASES)..."
          
          # List all model releases sorted by date
          gh release list --repo "${{ github.repository }}" --limit 100 \
            | grep -E "models-[0-9]{8}_[0-9]{6}" \
            | awk '{print $3}' \
            | sort -r \
            | tail -n +$((KEEP_RELEASES + 1)) \
            | while read -r tag; do
                echo "Deleting old release: $tag"
                gh release delete "$tag" --repo "${{ github.repository }}" --yes || true
                git push --delete origin "$tag" 2>/dev/null || true
              done
          
          echo "‚úÖ Cleanup complete"

      # ========================================
      # 6. Create GitHub Release
      # ========================================
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v2
        with:
          tag_name: models-${{ env.RUN_DATE }}
          name: "${{ env.IS_CANARY == 'true' && 'üß™' || 'ü§ñ' }} Models ${{ env.END_DATE }}"
          body: |
            ## ${{ env.IS_CANARY == 'true' && 'üß™ Canary' || 'üéØ Production' }} Training Results
            
            **Training Date**: ${{ env.END_DATE }}  
            **Run Date**: ${{ env.RUN_DATE }}  
            **Run ID**: ${{ github.run_id }}  
            **Trigger**: ${{ github.event_name }}
            
            ### üìä Summary
            - **Symbols Trained**: ${{ env.SYMBOLS }}
            - **Failed Symbols**: ${{ env.FAILED_SYMBOLS || 'none' }}
            - **Failure Rate**: ${{ env.FAILURE_RATE || '0' }}%
            - **Epochs**: ${{ env.EPOCHS }}
            
            ### üìà Model Statistics
            ```
            ${{ steps.model_stats.outputs.summary || '{}' }}
            ```
            
            <details>
            <summary>Full Statistics</summary>
            
            ```
            $(cat models_stats.json 2>/dev/null || echo '{}')
            ```
            </details>
            
            ### üì¶ Quick Start
            ```
            # Download latest stable release
            curl -L https://github.com/${{ github.repository }}/releases/download/models-latest/models.tar.gz -o models.tar.gz
            
            # Or specific date
            curl -L https://github.com/${{ github.repository }}/releases/download/models-${{ env.RUN_DATE }}/models-${{ env.RUN_DATE }}.tar.gz -o models.tar.gz
            
            # Extract
            tar -xzf models.tar.gz
            
            # Verify integrity
            sha256sum -c models-${{ env.RUN_DATE }}.tar.gz.sha256
            ```
            
            ### üîÑ Rollback
            To rollback to previous release:
            ```
            gh release list --repo ${{ github.repository }} | grep models-
            gh release download models-YYYYMMDD_HHMMSS -R ${{ github.repository }}
            ```
            
            ### ‚ö†Ô∏è Notes
            ${{ env.IS_CANARY == 'true' && '- **CANARY RELEASE**: Use for testing only, not recommended for production' || '' }}
            ${{ env.FAILED_SYMBOLS != '' && format('- Some models failed training: {0}', env.FAILED_SYMBOLS) || '' }}
          files: |
            models-${{ env.RUN_DATE }}.tar.gz
            models-${{ env.RUN_DATE }}.tar.gz.sha256
            models_stats.json
          draft: false
          prerelease: ${{ env.IS_CANARY == 'true' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # ========================================
      # 7. Update 'latest' Alias (production only)
      # ========================================
      - name: Update latest release alias
        if: success() && env.IS_CANARY != 'true'
        shell: bash
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          echo "üè∑Ô∏è  Updating models-latest alias..."
          
          # Create or force-update tag
          git tag -f models-latest
          git push -f origin models-latest
          
          # Delete old latest release
          gh release delete models-latest --repo "${{ github.repository }}" --yes 2>/dev/null || true
          
          # Create new latest release
          gh release create models-latest \
            --repo "${{ github.repository }}" \
            --title "ü§ñ Latest Models (Auto-updated)" \
            --notes "**Auto-updated**: $(date -u)  
          **Source Release**: models-${{ env.RUN_DATE }}  
          **Training Date**: ${{ env.END_DATE }}  
          
          This release is automatically updated after each successful nightly training.
          
          For production use, always use this \`models-latest\` release.
          For specific versions, see: https://github.com/${{ github.repository }}/releases" \
            "models-${{ env.RUN_DATE }}.tar.gz" \
            "models-${{ env.RUN_DATE }}.tar.gz.sha256" \
            "models_stats.json"
          
          echo "‚úÖ models-latest updated successfully"

      # ========================================
      # 8. Publish to Hugging Face (optional)
      # ========================================
      - name: Publish to Hugging Face Hub
        if: success() && env.HF_TOKEN != '' && env.IS_CANARY != 'true'
        shell: bash
        run: |
          python - <<'PYTHON_SCRIPT'
          import os, sys, pathlib
          from huggingface_hub import HfApi
          
          token = os.environ.get("HF_TOKEN")
          if not token:
              print("‚ö†Ô∏è  HF_TOKEN not set, skipping")
              sys.exit(0)
          
          repo_id = os.environ.get("HF_REPO")
          if not repo_id:
              owner = os.environ.get("GITHUB_REPOSITORY", "_/_").split("/")[0]
              repo_id = f"{owner}/ai-trading-models"
          
          private = os.environ.get("HF_PRIVATE", "true").lower() in ("1", "true", "yes")
          revision = os.environ.get("END_DATE", "main")
          
          if not pathlib.Path("models").exists():
              print("‚ö†Ô∏è  No 'models' directory found")
              sys.exit(0)
          
          print(f"üì§ Uploading to hf.co/{repo_id}@{revision}")
          
          try:
              api = HfApi(token=token)
              api.create_repo(repo_id=repo_id, repo_type="model", private=private, exist_ok=True)
              
              # Upload models
              api.upload_folder(
                  folder_path="models",
                  repo_id=repo_id,
                  repo_type="model",
                  commit_message=f"nightly: {revision}",
                  revision=revision
              )
              
              # Upload calibration
              if pathlib.Path("configs/calibration.json").exists():
                  api.upload_file(
                      path_or_fileobj="configs/calibration.json",
                      path_in_repo="calibration.json",
                      repo_id=repo_id,
                      repo_type="model",
                      commit_message=f"calibration: {revision}",
                      revision=revision
                  )
              
              print(f"‚úÖ Published to https://huggingface.co/{repo_id}/tree/{revision}")
          except Exception as e:
              print(f"‚ö†Ô∏è  Hugging Face upload failed: {e}")
              # Non-critical, don't fail workflow
          PYTHON_SCRIPT

      # ========================================
      # 9. Upload Artifacts (backup)
      # ========================================
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: training-artifacts-${{ env.RUN_DATE }}
          path: |
            models/**/*.joblib
            models/**/*.pkl
            configs/**/*.json
            logs/*.log
            models_stats.json
          if-no-files-found: warn
          retention-days: 7
          compression-level: 9

      # ========================================
      # 10. Monitoring & Summary
      # ========================================
      - name: Report metrics
        if: always()
        shell: bash
        run: |
          python - <<'PYTHON_SCRIPT'
          import os
          import json
          from datetime import datetime
          
          metrics = {
              "timestamp": datetime.utcnow().isoformat(),
              "workflow_id": os.environ["GITHUB_RUN_ID"],
              "trigger": os.environ.get("GITHUB_EVENT_NAME", "unknown"),
              "status": "success" if os.environ.get("FAILED_SYMBOLS", "") == "" else "partial_failure",
              "is_canary": os.environ.get("IS_CANARY", "false") == "true",
              "symbols_total": len(os.environ.get("SYMBOLS", "").split()),
              "symbols_failed": len(os.environ.get("FAILED_SYMBOLS", "").split()) if os.environ.get("FAILED_SYMBOLS") else 0,
              "failure_rate_pct": int(os.environ.get("FAILURE_RATE", "0")),
          }
          
          # Load model stats
          try:
              with open("models_stats.json") as f:
                  stats = json.load(f)
                  if "summary" in stats:
                      metrics.update({
                          "models_count": stats["summary"]["total_models"],
                          "total_size_mb": stats["summary"]["total_size_mb"],
                      })
          except:
              pass
          
          print("üìä Training Metrics:")
          print(json.dumps(metrics, indent=2))
          
          # Save for external monitoring
          with open("training_metrics.json", "w") as f:
              json.dump(metrics, f, indent=2)
          
          # TODO: Send to monitoring system
          # import requests
          # requests.post("https://metrics.arxora.com/training", json=metrics)
          PYTHON_SCRIPT

      - name: Generate workflow summary
        if: always()
        shell: bash
        run: |
          cat >> $GITHUB_STEP_SUMMARY <<EOF
          ## ${{ env.IS_CANARY == 'true' && 'üß™ Canary' || 'üéØ Production' }} Training Summary
          
          **Status**: ${{ job.status }}  
          **Date**: ${{ env.END_DATE }}  
          **Run ID**: ${{ github.run_id }}  
          **Runtime**: $(date -u)
          
          ### üìä Results
          - **Total Symbols**: $(echo "${{ env.SYMBOLS }}" | wc -w)
          - **Failed**: ${{ env.FAILED_COUNT || '0' }}
          - **Failure Rate**: ${{ env.FAILURE_RATE || '0' }}%
          
          ${{ env.FAILED_SYMBOLS != '' && format('### ‚ö†Ô∏è Failed Symbols\n{0}\n', env.FAILED_SYMBOLS) || '' }}
          
          ### üì¶ Artifacts
          - **Release**: [models-${{ env.RUN_DATE }}](https://github.com/${{ github.repository }}/releases/tag/models-${{ env.RUN_DATE }})
          ${{ env.IS_CANARY != 'true' && format('- **Latest Alias**: [models-latest](https://github.com/{0}/releases/tag/models-latest)', github.repository) || '' }}
          ${{ env.HF_TOKEN != '' && env.IS_CANARY != 'true' && format('- **Hugging Face**: [{0}](https://huggingface.co/{0})', env.HF_REPO) || '' }}
          
          ### üíæ Disk Usage
          \`\`\`
          $(df -h | grep -E 'Filesystem|/$')
          \`\`\`
          
          ### üìà Model Stats
          \`\`\`json
          $(cat models_stats.json 2>/dev/null | jq -r '.summary // {}' || echo '{}')
          \`\`\`
          EOF
          
          echo "‚úÖ Summary generated"

      - name: Notify on failure
        if: failure()
        shell: bash
        run: |
          echo "========================================="
          echo "‚ùå WORKFLOW FAILED"
          echo "========================================="
          echo "Run ID: ${{ github.run_id }}"
          echo "Logs: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          echo ""
          echo "Failed symbols: ${{ env.FAILED_SYMBOLS || 'unknown' }}"
          echo ""
          # TODO: Send alert to Telegram/Slack
          # curl -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
          #   -d "chat_id=${TELEGRAM_CHAT_ID}" \
          #   -d "text=‚ùå Nightly training failed: Run ${{ github.run_id }}"
